{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import inspect\n",
    "import time\n",
    "import logging\n",
    "\n",
    "from tqdm import trange, tqdm, tqdm_notebook, tqdm_pandas, tqdm_gui\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from transformers import BertConfig, BertModel, BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "                                            sentence  sentiment  polarity\n",
      "0  this is a very bland and inert production of o...          2         0\n",
      "1  i've seen this film in avant-premiere at imagi...          7         1\n",
      "2  revolt of the zombies (2 outta 5 stars) no, th...          4         0\n",
      "3  may contain minor spoilers.dressed to kill, ha...          7         1\n",
      "4  (spoilers)i shoulda figured. the dvd didn't ev...          2         0\n",
      "\n",
      "Test data:\n",
      "                                            sentence  sentiment  polarity\n",
      "0  i loved this movie so much. i'm a big fan of a...         10         1\n",
      "1  the stark, cold landscape of big sky country, ...          9         1\n",
      "2  this cheapo exploitation flick is some genuine...          2         0\n",
      "3  this movie has been promoting in everywhere in...          1         0\n",
      "4  this is a great off-the-wall romantic comedy a...          8         1\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(df):\n",
    "    \"\"\"\n",
    "    Preprocessing step\n",
    "    As above dataframe heads, there is a lot of <br /> character \n",
    "    \"\"\"\n",
    "    df.sentence = df.sentence.str.replace('<br />','')\n",
    "    df.sentence = df.sentence.str.lower()\n",
    "    return df\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "train = preprocessing(train)\n",
    "test = preprocessing(test)\n",
    "\n",
    "print('Train data:\\n{}\\n\\nTest data:\\n{}'.format(train.head(5), test.head(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization & Create inputs for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModelBonz():\n",
    "    def __init__(self, load_model=None, load_config=None, model='bert-base-uncased', max_len=512, batch_size=6):\n",
    "        self.pre_trained_model = model\n",
    "        self.max_len = max_len\n",
    "        self.batch_size = batch_size\n",
    "        # Setting model\n",
    "        if load_model is not None:\n",
    "            self.model = torch.load(load_model)\n",
    "        elif load_config is not None:\n",
    "            self.model = BertForSequenceClassification(load_config)\n",
    "            self.max_len = load_config.max_position_embeddings\n",
    "        else:    \n",
    "            self.model = BertForSequenceClassification.from_pretrained(self.pre_trained_model)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.pre_trained_model)\n",
    "        self.tokenizer.max_len = max_len\n",
    "        self.optimizer = AdamW(params = self.model.parameters(), lr=1e-5)\n",
    "    \n",
    "    def create_ids(self, sentences):\n",
    "        logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR) #Disable tokenizer logs, it's really annoy\n",
    "        input_ids = []\n",
    "        for sen in tqdm_notebook(sentences, desc=\"Create Ids\"):\n",
    "            tmp = self.tokenizer.encode(sen)\n",
    "            input_ids.append(tmp)\n",
    "        input_ids = pad_sequences(input_ids, \n",
    "                                  maxlen=self.max_len, \n",
    "                                  dtype='int64', \n",
    "                                  truncating='post', \n",
    "                                  padding='post')\n",
    "        return input_ids\n",
    "    \n",
    "    def prepare_data(self, input_ids, input_labels=None):\n",
    "        input_ids = torch.tensor(self.create_ids(input_ids))\n",
    "        if input_labels is None:\n",
    "            return DataLoader(TensorDataset(input_ids), \n",
    "                              batch_size=self.batch_size)\n",
    "        else:\n",
    "            input_labels = torch.tensor(input_labels)\n",
    "            return DataLoader(TensorDataset(input_ids, input_labels), \n",
    "                              batch_size=self.batch_size)\n",
    "        \n",
    "    def flat_accuracy(self, preds, labels):\n",
    "        pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "        labels_flat = labels.flatten()\n",
    "        return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "    \n",
    "    def train(self, dataloader, epochs=4):\n",
    "        self.train_loss_set =[]\n",
    "        for i in trange(epochs, desc=\"Epoch\"):\n",
    "            # Training model\n",
    "            self.model.to(device)\n",
    "            self.model.train()\n",
    "            tr_loss = 0\n",
    "            nb_tr_examples, nb_tr_steps = 0, 0\n",
    "            for input_ids, input_labels in tqdm_notebook(dataloader):\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.model(input_ids=input_ids.cuda(), labels=input_labels.cuda())[0]\n",
    "                self.train_loss_set.append(loss)    \n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                tr_loss += loss.item()\n",
    "                nb_tr_examples += input_ids.size(0)\n",
    "                nb_tr_steps += 1\n",
    "            print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "            # Evaluation\n",
    "            self.model.eval()\n",
    "            eval_loss, eval_accuracy = 0, 0\n",
    "            nb_eval_steps, nb_eval_examples = 0, 0\n",
    "            for input_ids, input_labels in dataloader:\n",
    "                with torch.no_grad():\n",
    "                    logits = self.model(input_ids.cuda())[0]\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = input_labels.to('cpu').numpy()\n",
    "                tmp_eval_accuracy = self.flat_accuracy(logits, label_ids)\n",
    "                eval_accuracy += tmp_eval_accuracy\n",
    "                nb_eval_steps += 1\n",
    "            print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "            \n",
    "            #Save model for each epoch:\n",
    "            filename = 'bert_512_epoch'+str(i)+'.sd'\n",
    "            filepath = './model/bert/'+filename\n",
    "            torch.save(self.model.state_dict(), filepath)\n",
    "            \n",
    "    def predict(self, test_data, test_labels):\n",
    "        test_ids = self.create_ids(test_data)\n",
    "        test_inputs = torch.tensor(test_ids)\n",
    "        test_dataloader = DataLoader(test_inputs, batch_size=self.batch_size)\n",
    "        \n",
    "        # Preditcion\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        self.predictions = []\n",
    "        for input_ids in tqdm_notebook(test_dataloader, desc=\"Predicting\"):\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(input_ids.to(device))[0]\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            self.predictions.append(logits)\n",
    "        self.predictions = [j for i in self.predictions for j in i]\n",
    "        self.predictions = np.argmax(self.predictions, axis=1)\n",
    "        print(classification_report(self.predictions, test_labels, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c910f3e1a0c4ed9bb2221a8efaffc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Create Ids', max=25000, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n",
      "Epoch:   0%|                                                                                     | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed780d8ea89e43c287a60e0c274b52c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4167), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.25542188695409984\n",
      "Validation Accuracy: 0.9586233101351972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|██████████████████▎                                                      | 1/4 [31:02<1:33:07, 1862.54s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ee33f8c3d14d458e70db1747197794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4167), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.12138432963141214\n",
      "Validation Accuracy: 0.9831213502919798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|███████████████████████████████████▌                                   | 2/4 [1:02:00<1:02:02, 1861.26s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a579c090e3be49b0867b75079c665d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4167), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.0652414504841357\n",
      "Validation Accuracy: 0.987840972722185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  75%|██████████████████████████████████████████████████████▊                  | 3/4 [1:33:04<31:02, 1862.00s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5981dc883ee7420fbe24dcaa0325137b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4167), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.04449292355971937\n",
      "Validation Accuracy: 0.9949204063674922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████████████████████████████████████████████████| 4/4 [2:04:08<00:00, 1862.48s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#Predict model\\nbert_model.predict(test_data=test.sentence, test_labels=test.polarity)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = BertModelBonz(batch_size=6)\n",
    "\n",
    "\n",
    "#Train model\n",
    "\n",
    "train.dataloader = bert_model.prepare_data(input_ids=train['sentence'], input_labels=train['polarity'])\n",
    "bert_model.train(train.dataloader)\n",
    "#torch.save(bert_model.model, 'bert_eb1024_1e5_e4.pth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d03a6dfbc64589ade76aea5e2451be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Create Ids', max=25000, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0141b7ba014416da72aa42d705ae60a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predicting', max=4167, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9211    0.9444    0.9326     12192\n",
      "           1     0.9458    0.9230    0.9343     12808\n",
      "\n",
      "   micro avg     0.9334    0.9334    0.9334     25000\n",
      "   macro avg     0.9334    0.9337    0.9334     25000\n",
      "weighted avg     0.9337    0.9334    0.9335     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Predict model\n",
    "bert_model.predict(test_data=test.sentence, test_labels=test.polarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  bert_512_epoch0.sd :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e6b4b403a04ac4af1440d73a9a2d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Create Ids', max=25000, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9859335ab3e447bad17a459a895c5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predicting', max=4167, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9084    0.9448    0.9262     12019\n",
      "           1     0.9469    0.9118    0.9290     12981\n",
      "\n",
      "   micro avg     0.9276    0.9276    0.9276     25000\n",
      "   macro avg     0.9276    0.9283    0.9276     25000\n",
      "weighted avg     0.9284    0.9276    0.9277     25000\n",
      "\n",
      "Model  bert_512_epoch1.sd :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90eba31506644c8090f2fed704692d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Create Ids', max=25000, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4d31e2277640bf9478e571f2bfac18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predicting', max=4167, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9376    0.9228    0.9301     12701\n",
      "           1     0.9215    0.9366    0.9290     12299\n",
      "\n",
      "   micro avg     0.9296    0.9296    0.9296     25000\n",
      "   macro avg     0.9296    0.9297    0.9296     25000\n",
      "weighted avg     0.9297    0.9296    0.9296     25000\n",
      "\n",
      "Model  bert_512_epoch2.sd :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234e18eef92046078296b37430e50f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Create Ids', max=25000, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b14122e3984426f9857d88df5d75b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predicting', max=4167, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9002    0.9581    0.9282     11744\n",
      "           1     0.9606    0.9059    0.9324     13256\n",
      "\n",
      "   micro avg     0.9304    0.9304    0.9304     25000\n",
      "   macro avg     0.9304    0.9320    0.9303     25000\n",
      "weighted avg     0.9322    0.9304    0.9305     25000\n",
      "\n",
      "Model  bert_512_epoch3.sd :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55a48cf516e487186ebd3e3c834a8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Create Ids', max=25000, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d00dfe05384049a313db06061f4cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predicting', max=4167, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9211    0.9444    0.9326     12192\n",
      "           1     0.9458    0.9230    0.9343     12808\n",
      "\n",
      "   micro avg     0.9334    0.9334    0.9334     25000\n",
      "   macro avg     0.9334    0.9337    0.9334     25000\n",
      "weighted avg     0.9337    0.9334    0.9335     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    filename = 'bert_512_epoch'+str(i)+'.sd'\n",
    "    filepath = './model/bert/'+filename\n",
    "    bert_model.model.load_state_dict(torch.load(filepath))\n",
    "    bert_model.model.eval()\n",
    "    print('Model ',filename,':')\n",
    "    bert_model.predict(test_data=test.sentence, test_labels=test.polarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
