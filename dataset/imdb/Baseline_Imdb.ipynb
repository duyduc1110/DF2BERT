{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>content</th>\n",
       "      <th>content_seg_no_stw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This is a very bland and inert production of o...</td>\n",
       "      <td>['This', 'bland', 'inert', 'production', 'one'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I've seen this film in avant-premiere at Imagi...</td>\n",
       "      <td>['I', \"'ve\", 'seen', 'film', 'avant-premiere',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>REVOLT OF THE ZOMBIES (2 outta 5 stars) No, th...</td>\n",
       "      <td>['REVOLT', 'OF', 'THE', 'ZOMBIES', '2', 'outta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>May contain minor spoilers.&lt;br /&gt;&lt;br /&gt;Dressed...</td>\n",
       "      <td>['May', 'contain', 'minor', 'spoilersDressed',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>(spoilers)&lt;br /&gt;&lt;br /&gt;I shoulda figured. The d...</td>\n",
       "      <td>['spoilersI', 'shoulda', 'figured', 'The', 'dv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tag                                            content  \\\n",
       "0    0  This is a very bland and inert production of o...   \n",
       "1    1  I've seen this film in avant-premiere at Imagi...   \n",
       "2    0  REVOLT OF THE ZOMBIES (2 outta 5 stars) No, th...   \n",
       "3    1  May contain minor spoilers.<br /><br />Dressed...   \n",
       "4    0  (spoilers)<br /><br />I shoulda figured. The d...   \n",
       "\n",
       "                                  content_seg_no_stw  \n",
       "0  ['This', 'bland', 'inert', 'production', 'one'...  \n",
       "1  ['I', \"'ve\", 'seen', 'film', 'avant-premiere',...  \n",
       "2  ['REVOLT', 'OF', 'THE', 'ZOMBIES', '2', 'outta...  \n",
       "3  ['May', 'contain', 'minor', 'spoilersDressed',...  \n",
       "4  ['spoilersI', 'shoulda', 'figured', 'The', 'dv...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# os.getcwd()\n",
    "path = 'C:/Users/doudi/OneDrive/Documents/jpconf2020/data/'\n",
    "os.chdir(path)\n",
    "\n",
    "file = 'Imdb_Seg_no_stopword.csv'\n",
    "f = pd.read_csv(file)\n",
    "f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import Convolution1D, Flatten, Dropout, MaxPool1D, GlobalAveragePooling1D\n",
    "from keras import initializers\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textCNN(texts, labels):\n",
    "    training_text, test_text, training_label, test_label = train_test_split(texts, labels, test_size=0.1)\n",
    "\n",
    "    token = Tokenizer(num_words = 20000)\n",
    "    token.fit_on_texts(training_text)\n",
    "    vocab = token.word_index\n",
    "\n",
    "    x_train_seq = token.texts_to_sequences(training_text)\n",
    "    x_test_seq = token.texts_to_sequences(test_text)\n",
    "    x_train = sequence.pad_sequences(x_train_seq, maxlen = 150)\n",
    "    x_test = sequence.pad_sequences(x_test_seq, maxlen = 150)\n",
    "\n",
    "    y_train = np_utils.to_categorical(training_label)\n",
    "    y_test = np_utils.to_categorical(test_label)\n",
    "\n",
    "    num_labels = 2\n",
    "    main_input = Input(shape=(150,), dtype='float64')\n",
    "    # pre-train embeddings\n",
    "    # embedder = Embedding(len(vocab) + 1, 300, input_length = 20, weights = [embedding_matrix], trainable = False)\n",
    "    # embed = embedder(main_input)\n",
    "\n",
    "    embedder = Embedding(len(vocab)+1, 300, input_length=150)\n",
    "    embed = embedder(main_input)\n",
    "\n",
    "    # filter size, region size\n",
    "    cnn = Convolution1D(2, 2, padding='same', strides = 1, activation='relu')(embed)\n",
    "    cnn = MaxPool1D(pool_size=4)(cnn)\n",
    "    flat = Flatten()(cnn)\n",
    "    drop = Dropout(0.2)(flat)\n",
    "    main_output = Dense(num_labels, activation='sigmoid')(drop)\n",
    "    model = Model(inputs = main_input, outputs = main_output)\n",
    "    model.summary()\n",
    "    \n",
    "    optmzr = optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer=optmzr, metrics = ['accuracy'])\n",
    "    train_history = model.fit(x_train, y_train, batch_size = 128, epochs = 100, \n",
    "                              verbose = 2, validation_data=(x_test, y_test))\n",
    "    pre_probability = model.predict(x_test)\n",
    "    predicted = pre_probability.argmax(axis=-1)\n",
    "\n",
    "    from sklearn import metrics\n",
    "    print(\"Classification report for classifier:\\n%s\\n\"\n",
    "          % ( metrics.classification_report(test_label, predicted)))\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(train_history.history['accuracy'])\n",
    "    plt.plot(train_history.history['val_accuracy'])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'], loc = \"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(train_history.history['loss'])\n",
    "    plt.plot(train_history.history['val_loss'])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'], loc = \"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(texts, labels):\n",
    "    training_text, test_text, training_label, test_label = train_test_split(texts, labels, test_size=0.1)\n",
    "\n",
    "    token = Tokenizer(num_words = 4000)\n",
    "    token.fit_on_texts(training_text)\n",
    "    print(token.document_count)\n",
    "\n",
    "    x_train_seq = token.texts_to_sequences(training_text)\n",
    "    x_test_seq = token.texts_to_sequences(test_text)\n",
    "    x_train = sequence.pad_sequences(x_train_seq, maxlen = 400)\n",
    "    x_test = sequence.pad_sequences(x_test_seq, maxlen = 400)\n",
    "\n",
    "    y_train = np_utils.to_categorical(training_label)\n",
    "    y_test = np_utils.to_categorical(test_label)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(output_dim=32,input_dim=4000,input_length=400))\n",
    "    model.add(Dropout(0.35))\n",
    "    model.add(SimpleRNN(units=16))\n",
    "    model.add(Dense(units=256,activation='relu'))\n",
    "    model.add(Dropout(0.35))\n",
    "    model.add(Dense(units=128,activation='relu'))\n",
    "    model.add(Dense(units=8,activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # checkpoint\n",
    "    # filepath=\"C:/Users/doudi/OneDrive/Documents/TMU-GIDS/Lab/Competition/AI cup 2019/weights.best.hdf5\"\n",
    "    # checkpoint= ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    train_history = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                              epochs=100, batch_size=128, verbose=1, validation_split=0.2)\n",
    "    scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "    print(scores[1])\n",
    "    \n",
    "    pre_probability = model.predict(x_test)\n",
    "    predicted = pre_probability.argmax(axis=-1)\n",
    "\n",
    "    from sklearn import metrics\n",
    "    print(\"Classification report for classifier:\\n%s\\n\"\n",
    "          % ( metrics.classification_report(test_label, predicted)))\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(train_history.history['accuracy'])\n",
    "    plt.plot(train_history.history['val_accuracy'])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'], loc = \"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(train_history.history['loss'])\n",
    "    plt.plot(train_history.history['val_loss'])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'], loc = \"upper left\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
