{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>content_seg</th>\n",
       "      <th>content_no_stw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>看 完 電影 後 似乎 做 上 時光 機回 歸到 年輕 的 熱血 想要 把 當下 的 感動 ...</td>\n",
       "      <td>['看', '完', '電影', '後', '似乎', '做', '上', '時光', '機...</td>\n",
       "      <td>['看', '完', '電影', '似乎', '時光', '機回', '歸到', '年輕',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>防 有雷 這部 電影 算是 今年 來還 不錯 好看 的 而 這个 不斷 重 復 的 概念 也...</td>\n",
       "      <td>['防', '有雷', '這部', '電影', '算是', '今年', '來還', '不錯'...</td>\n",
       "      <td>['防', '有雷', '這部', '電影', '算是', '來還', '不錯', '好看'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>詳細 劇情 就 不談 了 直接 說 我 的 想法 吧 我 本身 是 一個 保險 業務員 看到...</td>\n",
       "      <td>['詳細', '劇情', '就', '不談', '了', '直接', '說', '我', '...</td>\n",
       "      <td>['詳細', '劇情', '不談', '直接', '想法', '吧', '本身', '一個'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>賽 德克 巴萊 太陽旗 時光 之硯 部落 格 個人 板 劇照 圖文 版 如果 魏德聖 只是 ...</td>\n",
       "      <td>['賽', '德克', '巴萊', '太陽旗', '時光', '之硯', '部落', '格'...</td>\n",
       "      <td>['賽', '德克', '巴萊', '太陽旗', '時光', '之硯', '部落', '格'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>以下 爆雷慎入 今天 冒著風 大雨 大去 看 了 高年級 實習生 結果 看 完 大遠 百 早...</td>\n",
       "      <td>['以下', '爆雷慎入', '今天', '冒著風', '大雨', '大去', '看', '...</td>\n",
       "      <td>['以下', '爆雷慎入', '冒著風', '大雨', '大去', '看', '高年級', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tag  label                                            content  \\\n",
       "0   P      0  看 完 電影 後 似乎 做 上 時光 機回 歸到 年輕 的 熱血 想要 把 當下 的 感動 ...   \n",
       "1   P      0  防 有雷 這部 電影 算是 今年 來還 不錯 好看 的 而 這个 不斷 重 復 的 概念 也...   \n",
       "2   P      0  詳細 劇情 就 不談 了 直接 說 我 的 想法 吧 我 本身 是 一個 保險 業務員 看到...   \n",
       "3   P      0  賽 德克 巴萊 太陽旗 時光 之硯 部落 格 個人 板 劇照 圖文 版 如果 魏德聖 只是 ...   \n",
       "4   P      0  以下 爆雷慎入 今天 冒著風 大雨 大去 看 了 高年級 實習生 結果 看 完 大遠 百 早...   \n",
       "\n",
       "                                         content_seg  \\\n",
       "0  ['看', '完', '電影', '後', '似乎', '做', '上', '時光', '機...   \n",
       "1  ['防', '有雷', '這部', '電影', '算是', '今年', '來還', '不錯'...   \n",
       "2  ['詳細', '劇情', '就', '不談', '了', '直接', '說', '我', '...   \n",
       "3  ['賽', '德克', '巴萊', '太陽旗', '時光', '之硯', '部落', '格'...   \n",
       "4  ['以下', '爆雷慎入', '今天', '冒著風', '大雨', '大去', '看', '...   \n",
       "\n",
       "                                      content_no_stw  \n",
       "0  ['看', '完', '電影', '似乎', '時光', '機回', '歸到', '年輕',...  \n",
       "1  ['防', '有雷', '這部', '電影', '算是', '來還', '不錯', '好看'...  \n",
       "2  ['詳細', '劇情', '不談', '直接', '想法', '吧', '本身', '一個'...  \n",
       "3  ['賽', '德克', '巴萊', '太陽旗', '時光', '之硯', '部落', '格'...  \n",
       "4  ['以下', '爆雷慎入', '冒著風', '大雨', '大去', '看', '高年級', ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# os.getcwd()\n",
    "path = 'C:/Users/doudi/OneDrive/Documents/jpconf2020/ppt_movie/'\n",
    "os.chdir(path)\n",
    "\n",
    "file = 'PTT_movie_seg.csv'\n",
    "f = pd.read_csv(file)\n",
    "f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import Convolution1D, Flatten, Dropout, MaxPool1D, GlobalAveragePooling1D\n",
    "from keras import initializers\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textCNN(texts, labels):\n",
    "    training_text, test_text, training_label, test_label = train_test_split(texts, labels, test_size=0.1)\n",
    "\n",
    "    token = Tokenizer(num_words = 20000)\n",
    "    token.fit_on_texts(training_text)\n",
    "    vocab = token.word_index\n",
    "\n",
    "    x_train_seq = token.texts_to_sequences(training_text)\n",
    "    x_test_seq = token.texts_to_sequences(test_text)\n",
    "    x_train = sequence.pad_sequences(x_train_seq, maxlen = 150)\n",
    "    x_test = sequence.pad_sequences(x_test_seq, maxlen = 150)\n",
    "\n",
    "    y_train = np_utils.to_categorical(training_label)\n",
    "    y_test = np_utils.to_categorical(test_label)\n",
    "\n",
    "    num_labels = 2\n",
    "    main_input = Input(shape=(150,), dtype='float64')\n",
    "    # pre-train embeddings\n",
    "    # embedder = Embedding(len(vocab) + 1, 300, input_length = 20, weights = [embedding_matrix], trainable = False)\n",
    "    # embed = embedder(main_input)\n",
    "\n",
    "    embedder = Embedding(len(vocab)+1, 300, input_length=150)\n",
    "    embed = embedder(main_input)\n",
    "\n",
    "    # filter size, region size\n",
    "    cnn = Convolution1D(2, 2, padding='same', strides = 1, activation='relu')(embed)\n",
    "    cnn = MaxPool1D(pool_size=4)(cnn)\n",
    "    flat = Flatten()(cnn)\n",
    "    drop = Dropout(0.2)(flat)\n",
    "    main_output = Dense(num_labels, activation='sigmoid')(drop)\n",
    "    model = Model(inputs = main_input, outputs = main_output)\n",
    "    model.summary()\n",
    "    \n",
    "    optmzr = optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer=optmzr, metrics = ['accuracy'])\n",
    "    train_history = model.fit(x_train, y_train, batch_size = 128, epochs = 100, \n",
    "                              verbose = 2, validation_data=(x_test, y_test))\n",
    "    pre_probability = model.predict(x_test)\n",
    "    predicted = pre_probability.argmax(axis=-1)\n",
    "\n",
    "    from sklearn import metrics\n",
    "    print(\"Classification report for classifier:\\n%s\\n\"\n",
    "          % ( metrics.classification_report(test_label, predicted)))\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(train_history.history['accuracy'])\n",
    "    plt.plot(train_history.history['val_accuracy'])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'], loc = \"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(train_history.history['loss'])\n",
    "    plt.plot(train_history.history['val_loss'])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'], loc = \"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(texts, labels):\n",
    "    training_text, test_text, training_label, test_label = train_test_split(texts, labels, test_size=0.1)\n",
    "\n",
    "    token = Tokenizer(num_words = 4000)\n",
    "    token.fit_on_texts(training_text)\n",
    "    print(token.document_count)\n",
    "\n",
    "    x_train_seq = token.texts_to_sequences(training_text)\n",
    "    x_test_seq = token.texts_to_sequences(test_text)\n",
    "    x_train = sequence.pad_sequences(x_train_seq, maxlen = 400)\n",
    "    x_test = sequence.pad_sequences(x_test_seq, maxlen = 400)\n",
    "\n",
    "    y_train = np_utils.to_categorical(training_label)\n",
    "    y_test = np_utils.to_categorical(test_label)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(output_dim=32,input_dim=4000,input_length=400))\n",
    "    model.add(Dropout(0.35))\n",
    "    model.add(SimpleRNN(units=16))\n",
    "    model.add(Dense(units=256,activation='relu'))\n",
    "    model.add(Dropout(0.35))\n",
    "    model.add(Dense(units=128,activation='relu'))\n",
    "    model.add(Dense(units=8,activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # checkpoint\n",
    "    # filepath=\"C:/Users/doudi/OneDrive/Documents/TMU-GIDS/Lab/Competition/AI cup 2019/weights.best.hdf5\"\n",
    "    # checkpoint= ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    train_history = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                              epochs=100, batch_size=128, verbose=1, validation_split=0.2)\n",
    "    scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "    print(scores[1])\n",
    "    \n",
    "    pre_probability = model.predict(x_test)\n",
    "    predicted = pre_probability.argmax(axis=-1)\n",
    "\n",
    "    from sklearn import metrics\n",
    "    print(\"Classification report for classifier:\\n%s\\n\"\n",
    "          % ( metrics.classification_report(test_label, predicted)))\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(train_history.history['accuracy'])\n",
    "    plt.plot(train_history.history['val_accuracy'])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'], loc = \"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(train_history.history['loss'])\n",
    "    plt.plot(train_history.history['val_loss'])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'], loc = \"upper left\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
